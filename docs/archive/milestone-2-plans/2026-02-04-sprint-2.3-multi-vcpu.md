# Sprint 2.3: Multi-vCPU Support Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Support multiple vCPUs with scheduling and per-vCPU state.

**Architecture:** Refactor VM to hold an array of vCPUs. Implement a simple round-robin scheduler. Each vCPU has independent context and interrupt state.

**Tech Stack:** Rust (no_std), single-threaded (physical CPU)

---

## Task 1: Refactor Vcpu for Multi-Core

**Files:**
- Modify: `src/vcpu.rs`
- Modify: `src/vm.rs`
- Create: `tests/test_multi_vcpu.rs`
- Modify: `tests/mod.rs`

**Step 1: Write the failing test**

```rust
// tests/test_multi_vcpu.rs

pub fn run_multi_vcpu_test() {
    crate::uart_puts(b"\n[MULTI] Testing multi-vCPU support...\n");

    let mut vm = crate::vm::Vm::new();

    let vcpu0 = vm.create_vcpu(0);
    assert!(vcpu0.is_ok());
    crate::uart_puts(b"[MULTI] vCPU 0 created\n");

    let vcpu1 = vm.create_vcpu(1);
    assert!(vcpu1.is_ok());
    crate::uart_puts(b"[MULTI] vCPU 1 created\n");

    // Each vCPU should have independent state
    {
        let v0 = vm.vcpu_mut(0).unwrap();
        v0.context_mut().set_gpr(0, 0x1111);
    }
    {
        let v1 = vm.vcpu_mut(1).unwrap();
        v1.context_mut().set_gpr(0, 0x2222);
    }

    assert_eq!(vm.vcpu(0).unwrap().context().get_gpr(0), 0x1111);
    assert_eq!(vm.vcpu(1).unwrap().context().get_gpr(0), 0x2222);
    crate::uart_puts(b"[MULTI] vCPU state independence OK\n");

    crate::uart_puts(b"[MULTI] Multi-vCPU test passed!\n");
}
```

**Step 2: Run test to verify it fails**

Run: `make build`
Expected: FAIL - Vm::create_vcpu doesn't exist

**Step 3: Add vcpu_id to Vcpu**

```rust
// src/vcpu.rs - modify Vcpu struct

pub struct Vcpu {
    id: usize,
    context: VcpuContext,
    virt_irq: VirtualInterruptState,
    state: VcpuState,
}

impl Vcpu {
    pub fn new(id: usize) -> Self {
        Self {
            id,
            context: VcpuContext::new(),
            virt_irq: VirtualInterruptState::new(),
            state: VcpuState::Uninitialized,
        }
    }

    pub fn id(&self) -> usize {
        self.id
    }

    pub fn context(&self) -> &VcpuContext {
        &self.context
    }

    pub fn context_mut(&mut self) -> &mut VcpuContext {
        &mut self.context
    }
}
```

**Step 4: Refactor VM for multiple vCPUs**

```rust
// src/vm.rs - refactor for array of vCPUs

use crate::vcpu::Vcpu;

pub const MAX_VCPUS: usize = 8;

pub struct Vm {
    vcpus: [Option<Vcpu>; MAX_VCPUS],
    vcpu_count: usize,
    // ... other fields
}

impl Vm {
    pub fn new() -> Self {
        Self {
            vcpus: Default::default(),
            vcpu_count: 0,
            // ... init other fields
        }
    }

    pub fn create_vcpu(&mut self, vcpu_id: usize) -> Result<&mut Vcpu, &'static str> {
        if vcpu_id >= MAX_VCPUS {
            return Err("vCPU ID out of range");
        }
        if self.vcpus[vcpu_id].is_some() {
            return Err("vCPU already exists");
        }

        let vcpu = Vcpu::new(vcpu_id);
        self.vcpus[vcpu_id] = Some(vcpu);
        self.vcpu_count += 1;

        Ok(self.vcpus[vcpu_id].as_mut().unwrap())
    }

    pub fn vcpu(&self, vcpu_id: usize) -> Option<&Vcpu> {
        self.vcpus.get(vcpu_id).and_then(|v| v.as_ref())
    }

    pub fn vcpu_mut(&mut self, vcpu_id: usize) -> Option<&mut Vcpu> {
        self.vcpus.get_mut(vcpu_id).and_then(|v| v.as_mut())
    }

    pub fn vcpu_count(&self) -> usize {
        self.vcpu_count
    }
}
```

**Step 5: Run test to verify it passes**

Run: `make build && make run`
Expected: PASS

**Step 6: Commit**

```bash
git add src/vcpu.rs src/vm.rs tests/test_multi_vcpu.rs tests/mod.rs
git commit -m "$(cat <<'EOF'
feat(vcpu): refactor VM for multi-vCPU support

Add per-vCPU state management with up to 8 vCPUs per VM.
Each vCPU has independent context and interrupt state.

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 2: Implement Simple Round-Robin Scheduler

**Files:**
- Create: `src/scheduler.rs`
- Modify: `src/lib.rs`
- Create: `tests/test_scheduler.rs`

**Step 1: Write the failing test**

```rust
// tests/test_scheduler.rs

pub fn run_scheduler_test() {
    crate::uart_puts(b"\n[SCHED] Testing scheduler...\n");

    use crate::scheduler::Scheduler;

    let mut sched = Scheduler::new();

    sched.add_vcpu(0);
    sched.add_vcpu(1);
    sched.add_vcpu(2);

    assert_eq!(sched.pick_next(), Some(0));
    crate::uart_puts(b"[SCHED] First pick OK\n");

    sched.yield_current();
    assert_eq!(sched.pick_next(), Some(1));
    crate::uart_puts(b"[SCHED] Round-robin OK\n");

    sched.yield_current();
    assert_eq!(sched.pick_next(), Some(2));
    sched.yield_current();
    assert_eq!(sched.pick_next(), Some(0)); // Wrap around
    crate::uart_puts(b"[SCHED] Wrap-around OK\n");

    crate::uart_puts(b"[SCHED] Scheduler test passed!\n");
}
```

**Step 2: Run test to verify it fails**

Run: `make build`
Expected: FAIL

**Step 3: Implement scheduler**

```rust
// src/scheduler.rs

//! Simple round-robin vCPU scheduler

use crate::vm::MAX_VCPUS;

#[derive(Clone, Copy, PartialEq)]
pub enum RunState {
    None,
    Ready,
    Running,
    Blocked,
}

pub struct Scheduler {
    states: [RunState; MAX_VCPUS],
    current: Option<usize>,
    next_idx: usize,
}

impl Scheduler {
    pub const fn new() -> Self {
        Self {
            states: [RunState::None; MAX_VCPUS],
            current: None,
            next_idx: 0,
        }
    }

    pub fn add_vcpu(&mut self, vcpu_id: usize) {
        if vcpu_id < MAX_VCPUS {
            self.states[vcpu_id] = RunState::Ready;
        }
    }

    pub fn remove_vcpu(&mut self, vcpu_id: usize) {
        if vcpu_id < MAX_VCPUS {
            self.states[vcpu_id] = RunState::None;
            if self.current == Some(vcpu_id) {
                self.current = None;
            }
        }
    }

    pub fn pick_next(&mut self) -> Option<usize> {
        if let Some(id) = self.current {
            if self.states[id] == RunState::Running {
                return self.current;
            }
        }

        for i in 0..MAX_VCPUS {
            let idx = (self.next_idx + i) % MAX_VCPUS;
            if self.states[idx] == RunState::Ready {
                self.current = Some(idx);
                self.states[idx] = RunState::Running;
                return Some(idx);
            }
        }

        None
    }

    pub fn yield_current(&mut self) {
        if let Some(id) = self.current {
            self.states[id] = RunState::Ready;
            self.current = None;
            self.next_idx = (id + 1) % MAX_VCPUS;
        }
    }

    pub fn block_current(&mut self) {
        if let Some(id) = self.current {
            self.states[id] = RunState::Blocked;
            self.current = None;
            self.next_idx = (id + 1) % MAX_VCPUS;
        }
    }

    pub fn unblock(&mut self, vcpu_id: usize) {
        if vcpu_id < MAX_VCPUS && self.states[vcpu_id] == RunState::Blocked {
            self.states[vcpu_id] = RunState::Ready;
        }
    }

    pub fn current(&self) -> Option<usize> {
        self.current
    }
}
```

```rust
// src/lib.rs - add module

pub mod scheduler;
```

**Step 4: Run test to verify it passes**

Run: `make build && make run`
Expected: PASS

**Step 5: Commit**

```bash
git add src/scheduler.rs src/lib.rs tests/test_scheduler.rs tests/mod.rs
git commit -m "$(cat <<'EOF'
feat(sched): add round-robin vCPU scheduler

Implement simple scheduler with ready/running/blocked states
and round-robin selection policy.

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 3: Integrate Scheduler with VM

**Files:**
- Modify: `src/vm.rs`
- Create: `tests/test_vm_scheduler.rs`

**Step 1: Write the failing test**

```rust
// tests/test_vm_scheduler.rs

pub fn run_vm_scheduler_test() {
    crate::uart_puts(b"\n[VM SCHED] Testing VM with scheduler...\n");

    let mut vm = crate::vm::Vm::new();

    vm.create_vcpu(0).unwrap();
    vm.create_vcpu(1).unwrap();

    // First schedule should return vCPU 0
    let next = vm.schedule();
    assert_eq!(next, Some(0));
    crate::uart_puts(b"[VM SCHED] First schedule OK\n");

    // Yield and schedule should return vCPU 1
    vm.yield_current();
    let next = vm.schedule();
    assert_eq!(next, Some(1));
    crate::uart_puts(b"[VM SCHED] Yield and reschedule OK\n");

    // Block current and schedule should return vCPU 0
    vm.block_current();
    let next = vm.schedule();
    assert_eq!(next, Some(0));
    crate::uart_puts(b"[VM SCHED] Block and reschedule OK\n");

    // Unblock vCPU 1 and yield should make it available
    vm.unblock(1);
    vm.yield_current();
    let next = vm.schedule();
    assert_eq!(next, Some(1));
    crate::uart_puts(b"[VM SCHED] Unblock OK\n");

    crate::uart_puts(b"[VM SCHED] VM scheduler test passed!\n");
}
```

**Step 2: Run test to verify it fails**

Run: `make build`
Expected: FAIL

**Step 3: Add scheduler to VM**

```rust
// src/vm.rs - add scheduler integration

use crate::scheduler::Scheduler;

pub struct Vm {
    vcpus: [Option<Vcpu>; MAX_VCPUS],
    vcpu_count: usize,
    scheduler: Scheduler,
    // ... other fields
}

impl Vm {
    pub fn new() -> Self {
        Self {
            vcpus: Default::default(),
            vcpu_count: 0,
            scheduler: Scheduler::new(),
            // ... init other fields
        }
    }

    pub fn create_vcpu(&mut self, vcpu_id: usize) -> Result<&mut Vcpu, &'static str> {
        if vcpu_id >= MAX_VCPUS {
            return Err("vCPU ID out of range");
        }
        if self.vcpus[vcpu_id].is_some() {
            return Err("vCPU already exists");
        }

        let vcpu = Vcpu::new(vcpu_id);
        self.vcpus[vcpu_id] = Some(vcpu);
        self.vcpu_count += 1;
        self.scheduler.add_vcpu(vcpu_id);

        Ok(self.vcpus[vcpu_id].as_mut().unwrap())
    }

    pub fn schedule(&mut self) -> Option<usize> {
        self.scheduler.pick_next()
    }

    pub fn run_current(&mut self) -> Result<(), &'static str> {
        let vcpu_id = self.scheduler.current().ok_or("No current vCPU")?;
        let vcpu = self.vcpus[vcpu_id].as_mut().ok_or("vCPU not found")?;
        vcpu.run()
    }

    pub fn mark_current_done(&mut self) {
        if let Some(id) = self.scheduler.current() {
            self.scheduler.remove_vcpu(id);
        }
    }

    pub fn yield_current(&mut self) {
        self.scheduler.yield_current();
    }

    pub fn block_current(&mut self) {
        self.scheduler.block_current();
    }

    pub fn unblock(&mut self, vcpu_id: usize) {
        self.scheduler.unblock(vcpu_id);
    }
}
```

**Step 4: Run test to verify it passes**

Run: `make build && make run`
Expected: PASS

**Step 5: Commit**

```bash
git add src/vm.rs tests/test_vm_scheduler.rs tests/mod.rs
git commit -m "$(cat <<'EOF'
feat(vm): integrate scheduler with VM

Add Scheduler to VM for multi-vCPU execution with schedule(),
run_current(), yield_current(), and block/unblock APIs.

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 4: Multi-vCPU Execution Test

**Files:**
- Create: `tests/test_multi_vcpu_run.rs`

**Step 1: Write the integration test**

```rust
// tests/test_multi_vcpu_run.rs

pub fn run_multi_vcpu_execution_test() {
    crate::uart_puts(b"\n[MULTI RUN] Testing multi-vCPU execution...\n");

    let mut vm = crate::vm::Vm::new();

    // Guest code: store vCPU ID in x0 and exit
    // Each vCPU runs the same code but returns different value
    let guest_code: [u32; 4] = [
        0xD2800000, // MOV x0, #0 (will be patched per vCPU)
        0xD4000002, // HVC #0
        0xD503201F, // NOP
        0xD503201F, // NOP
    ];

    let guest_base = 0x4000_0000u64;

    // Create 2 vCPUs
    {
        let vcpu0 = vm.create_vcpu(0).unwrap();
        vcpu0.set_entry(guest_base);
        vcpu0.reset();
    }
    {
        let vcpu1 = vm.create_vcpu(1).unwrap();
        vcpu1.set_entry(guest_base + 0x100);
        vcpu1.reset();
    }

    crate::uart_puts(b"[MULTI RUN] Created 2 vCPUs\n");

    // Run scheduler loop
    let mut completed = 0;
    let mut iterations = 0;

    while completed < 2 && iterations < 10 {
        if let Some(vcpu_id) = vm.schedule() {
            match vm.run_current() {
                Ok(()) => {
                    crate::uart_puts(b"[MULTI RUN] vCPU exited normally\n");
                    vm.mark_current_done();
                    completed += 1;
                }
                Err("WFI") => {
                    vm.block_current();
                }
                Err(_) => {
                    vm.mark_current_done();
                    completed += 1;
                }
            }
        } else {
            break;
        }
        iterations += 1;
    }

    assert_eq!(completed, 2, "Both vCPUs should complete");
    crate::uart_puts(b"[MULTI RUN] Multi-vCPU execution test passed!\n");
}
```

**Step 2: Run test**

Run: `make build && make run`
Expected: PASS

**Step 3: Commit**

```bash
git add tests/test_multi_vcpu_run.rs tests/mod.rs
git commit -m "$(cat <<'EOF'
test(vcpu): add multi-vCPU execution integration test

Verify scheduler correctly runs multiple vCPUs with
proper state transitions and completion tracking.

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Summary

**Sprint 2.3 Tasks:**
1. Refactor Vcpu for multi-core (add ID, array in VM)
2. Implement round-robin scheduler
3. Integrate scheduler with VM
4. Multi-vCPU execution test

**Estimated time: 15-20 hours**

**Dependencies:** Sprint 2.1, Sprint 2.2 (for dynamic memory)

**Next:** Sprint 2.4 - API Documentation
